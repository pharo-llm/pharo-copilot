<!DOCTYPE HTML>
<html>
		<head>
	    <meta charset="UTF-8" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
	    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<link rel="icon" type="image/png" href="/Pharo-Copilot/files/favicon.ico">
	    <link rel="stylesheet" type="text/css" href="/Pharo-Copilot/files/simple.css" /> 
	    <title>Pharo-Copilot</title>
	</head>
	<body>
	
	<div id="header">
	<div id="headerSiteTitle">
	Pharo-Copilot Documentation
	</div>
	<div id="headerPageTitle"> 
	</div>
</div>
	<div id="menu">
	<div id="toc">
		<div id="tocItem"><a href="/Pharo-Copilot/index.html">Home</a>
		</div>
		<div id="tocItem"><a href="/Pharo-Copilot/publications.html">Publications</a>
		</div>	
		<div id="tocItem"><a href="/Pharo-Copilot/news/index.html">News</a>
		</div>
	</div>
</div>    <!--Closing menu -->


	<div id="mainContent">
		
		<div id="personalDetails">
		<div><img src="/Pharo-Copilot/files/logo.png" width="128px"></div>
	</div>

	<h1>Pharo Copilot – System Documentation</h1><p>Table of Contents</p><ol><li>Executive Summary</li><li>Architecture Overview</li><li>Core Components</li><li>Ollama Integration</li><li>Completion Engine</li><li>Evaluation System</li><li>Fill-in-the-Middle (FIM) Templates</li><li>Installation & Setup</li><li>Usage Guide</li><li>. Configuration & Settings</li><li>. Extension Points</li><li>. Troubleshooting</li><li>. Testing Suite</li></ol><p>---</p><h2>1. Executive Summary</h2><p>AI-Pharo-Copilot is an AI-powered code completion assistant integrated directly into the Pharo Smalltalk development environment. It provides intelligent, context-aware code suggestions using Large Language Models (LLMs) running locally via Ollama, eliminating the need to send code to external servers.</p><h3>Key Features</h3><ul><li><strong>Local LLM Integration</strong>: Runs models locally via Ollama for complete privacy</li><li><strong>Context-Aware Completions</strong>: Analyzes class structure, methods, and surrounding code</li><li><strong>Fill-in-the-Middle (FIM) Support</strong>: Completes code based on prefix and suffix context</li><li><strong>Real-time Evaluation</strong>: Tracks suggestion acceptance rates and quality metrics</li><li><strong>Asynchronous Processing</strong>: Non-blocking completion fetching for smooth editing</li><li><strong>Comprehensive Logging</strong>: Detailed activity tracking for debugging and analysis</li><li><strong>Auto-Installation</strong>: Automatically pulls recommended models when missing</li><li><strong>Extensive Testing</strong>: Full test suite with mock support for reliable development</li></ul><h3>Technology Stack</h3><ul><li><strong>Language</strong>: Pharo Smalltalk (13 & 14 compatible)</li><li><strong>LLM Backend</strong>: Ollama (local inference server)</li><li><strong>Completion Framework</strong>: Pharo's native Completion Engine</li><li><strong>HTTP Client</strong>: ZnClient (Zinc HTTP Components)</li><li><strong>Persistence</strong>: STON (Smalltalk Object Notation) and JSONL</li><li><strong>Logging</strong>: File-based logging with structured events</li></ul><p>---</p><h2>2. Architecture Overview</h2><p>AI-Pharo-Copilot follows a layered architecture with clear separation of concerns:</p><pre><code>┌─────────────────────────────────────────────────────────┐│                   Editor Integration                    ││        (RubSmalltalkEditor, Completion Engine)          │└────────────────────┬────────────────────────────────────┘                     │┌────────────────────▼────────────────────────────────────┐│                 Completion Layer                        ││  (CoCompletionEnginePharoCopilot, ResultSetBuilder)    │└────────────────────┬────────────────────────────────────┘                     │┌────────────────────▼────────────────────────────────────┐│                   Client Layer                          ││    (OllamaClient, HTTP Transport, FIM Template)         │└────────────────────┬────────────────────────────────────┘                     │┌────────────────────▼────────────────────────────────────┐│                Evaluation & Logging                     ││  (CoSuggestionEvaluator, CoCopilotLogger, Reports)      │└────────────────────┬────────────────────────────────────┘                     │┌────────────────────▼────────────────────────────────────┐│              Settings & Configuration                   ││  (CopilotSettings, OModelRegistry, Model Catalog)       │└─────────────────────────────────────────────────────────┘</code></pre><h3>Package Structure</h3><table><tr><th>Package</th><th>Purpose</th></tr><tr><td><strong>AI-Pharo-Copilot</strong></td><td>Core completion engine, result builder, context, and logging</td></tr><tr><td><strong>AI-Pharo-Copilot-Ollama</strong></td><td>Ollama client, HTTP transport, model registry, and settings</td></tr><tr><td><strong>AI-Pharo-Copilot-Evaluator</strong></td><td>Suggestion evaluation, metrics tracking, and reporting</td></tr><tr><td><strong>AI-Pharo-Copilot-Tests</strong></td><td>Comprehensive test suite with mock infrastructure</td></tr></table><p>---</p><h2>3. Core Components</h2><h3>3.1 CoCompletionEnginePharoCopilot (Completion Engine)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot/CoCompletionEnginePharoCopilot.class.st</code></p><p><strong>Purpose</strong>: The main completion engine that integrates with Pharo's editor.</p><p><strong>Responsibilities</strong>:</p><ul><li>Provides completion builder instance</li><li>Handles token replacement in editor</li><li>Maintains cursor position after insertion</li><li>Logs completion requests</li></ul><p><strong>Key Methods</strong>:</p><pre><code>CoCompletionEnginePharoCopilot >> completionBuilder    "Returns memoized CoPharoCopilotResultSetBuilder instance"    ^ completionBuilder ifNil: [         completionBuilder := CoPharoCopilotResultSetBuilder new ]CoCompletionEnginePharoCopilot >> replaceTokenInEditorWith: newString    "Replaces text and maintains original cursor position"    | originalCaretPosition |    originalCaretPosition := self editor caret.    super replaceTokenInEditorWith: newString.    self editor selectAt: originalCaretPosition.</code></pre><p><strong>Integration</strong>:</p><pre><code>"Set as active completion engine"RubSmalltalkEditor completionEngineClass: CoCompletionEnginePharoCopilot</code></pre><p>---</p><h3>3.2 CoPharoCopilotResultSetBuilder (Result Builder)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot/CoPharoCopilotResultSetBuilder.class.st</code></p><p><strong>Purpose</strong>: Builds completion result sets by coordinating with Ollama and processing responses.</p><p><strong>Responsibilities</strong>:</p><ul><li>Extracts code context (class definition, methods, prefix/suffix)</li><li>Dispatches asynchronous completion requests</li><li>Cleans and normalizes LLM responses</li><li>Applies suggestions to editor</li></ul><p><strong>Key Attributes</strong>:</p><pre><code>completionContext    "The completion context from editor"</code></pre><p><strong>Key Methods</strong>:</p><pre><code>buildCompletion    "Main entry point - dispatches async fetch and returns empty result set"    classContextFor: aContext    "Extracts class definition and all methods for context"    processCompletionFor: aContext prefix: prefix suffix: suffix contextInfo: dict    "Background worker that queries Ollama and applies result"    cleanedContentFrom: aString    "Removes markdown fences and language specifiers"</code></pre><p><strong>Process Flow</strong>:</p><ol><li><strong>Context Extraction</strong>: Gathers class definition, instance methods, class methods</li><li><strong>Async Dispatch</strong>: Forks background process at <code>userBackgroundPriority</code></li><li><strong>API Call</strong>: Sends request to OllamaClient with FIM template</li><li><strong>Response Cleaning</strong>: Removes <code></code>`smalltalk fences and metadata</li><li><strong>Editor Update</strong>: Applies cleaned suggestion to editor</li><li><strong>Logging</strong>: Records all stages with detailed context</li></ol><p><strong>Context Structure</strong>:</p><pre><code>contextInfo := Dictionary new    at: #contextClass put: context class name;    at: #cursorPosition put: context position;    at: #sourceSize put: context source size;    at: #fullSource put: context source;    at: #prefix put: prefix;    at: #suffix put: suffix;    at: #classContextLength put: classContext size;    yourself.</code></pre><p>---</p><h3>3.3 CoPharoCopilotContext (Completion Context)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot/CoPharoCopilotContext.class.st</code></p><p><strong>Purpose</strong>: Specialized completion context for Pharo Copilot.</p><p><strong>Initialization</strong>:</p><pre><code>CoPharoCopilotContext >> initialize    super initialize.    completionBuilder := CoPharoCopilotResultSetBuilder         initializeOnContext: self</code></pre><p>---</p><h3>3.4 CoCopilotEntry (Suggestion Entry)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot/CoCopilotEntry.class.st</code></p><p><strong>Purpose</strong>: Represents a single completion suggestion.</p><p><strong>Attributes</strong>:</p><pre><code>text    "The completion text"</code></pre><p><strong>Key Methods</strong>:</p><pre><code>CoCopilotEntry class >> contents: aString    "Factory method"    ^ self new text: aString; yourself.activateOn: aCoCompletionContext    "Apply suggestion to editor"    aCoCompletionContext replaceTokenInEditorWith: textdisplayString    "Truncate long suggestions for display"    ^ text size > 120        ifTrue: [ (text copyFrom: 1 to: 117), '…' ]        ifFalse: [ text ]</code></pre><p>---</p><h3>3.5 CoCopilotLogger (Activity Logger)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot/CoCopilotLogger.class.st</code></p><p><strong>Purpose</strong>: Centralized logging system for all copilot activities.</p><p><strong>Log Files</strong>:</p><ul><li><strong>Activity Log</strong>: <code>pharo-copilot/copilot-logs/copilot.log</code></li><li><strong>Evaluation Log</strong>: <code>pharo-copilot/copilot-logs/copilot-evaluation-log.jsonl</code></li></ul><p><strong>Class Variables</strong>:</p><pre><code>logFileReferencelogsDirectoryReferenceevaluationLogFileReference</code></pre><p><strong>Key Methods</strong>:</p><pre><code>CoCopilotLogger class >> logFrontEndEvent: eventName details: aDictionary    "Log user-facing events"    CoCopilotLogger class >> logBackEndEvent: eventName details: aDictionary    "Log backend/API events"    CoCopilotLogger class >> logError: eventName origin: originSymbol     exception: anException payload: aDictionary    "Log errors with stack traces"</code></pre><p><strong>Log Format</strong>:</p><pre><code>===== [FRONTEND] Preparing completion request @ 2025-01-15 14:23:45 =====  - contextClass: CoPharoCopilotContext  - cursorPosition: 45  - sourceSize: 120  - fullSource: Object subclass: #MyClass...===== [BACKEND] Dispatching generate request @ 2025-01-15 14:23:46 =====  - endpoint: api/generate  - modelFullName: pharo-coder-1.5b-fim-f16.gguf:latest  - optionsSnapshot: {"task": "fill-in-the-middle"}===== [ERROR] Asynchronous completion failed @ 2025-01-15 14:23:50 =====  - origin: CoPharoCopilotResultSetBuilder  - error: Connection timeout  - stackTrace: ...</code></pre><p><strong>Enabling/Disabling</strong>:</p><pre><code>CopilotSettings loggingEnabled: true.   "Enable"CopilotSettings loggingEnabled: false.  "Disable"</code></pre><p>---</p><h2>4. Ollama Integration</h2><h3>4.1 OllamaClient (REST API Client)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Ollama/OllamaClient.class.st</code></p><p><strong>Purpose</strong>: Simple client for invoking the Ollama REST API.</p><p><strong>Attributes</strong>:</p><pre><code>transport    "OAHttpTransport instance"modelSpec    "OModelSpec - current model"stream       "Boolean - streaming mode (currently false)"format       "Output format (optional)"options      "Dictionary of Ollama options"</code></pre><p><strong>Key Methods</strong>:</p><pre><code>generate: aPromptString    "Main API call to /api/generate endpoint"    | payload resp normalized |    self isNullModel ifTrue: [ ^ self class nullModelResponseString ].    payload := Dictionary new        at: #model put: modelSpec fullName;        at: #prompt put: aPromptString;        at: #stream put: stream;        yourself.    resp := transport postJsonAt: 'api/generate' body: payload.    ^ self normalizeResponse: respgenerateForPrefix: prefixString suffix: suffixString context: contextString    "Fill-in-the-middle completion"    | prompt originalOptions response |    prompt := self        expandFimTemplate: CopilotSettings fimTemplate        prefix: prefixString        suffix: suffixString        context: contextString.    originalOptions := options copy.    options at: #task put: 'fill-in-the-middle'.    response := self generate: prompt.    options := originalOptions.    ^ responselistModels    "Query available models from Ollama"    ^ transport getJsonAt: 'api/tags'</code></pre><p><strong>Null Model</strong>:</p><p>When no model is configured, Copilot uses a special "null model":</p><pre><code>OllamaClient class >> nullModelFullName    ^ 'pharo-copilot-null'OllamaClient class >> nullModelResponseString    ^ 'no output, please configure.'</code></pre><p>---</p><h3>4.2 OAHttpTransport (HTTP Client)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Ollama/OAHttpTransport.class.st</code></p><p><strong>Purpose</strong>: Performs HTTP JSON requests against the local Ollama server.</p><p><strong>Attributes</strong>:</p><pre><code>host             "Server host (default: 127.0.0.1)"port             "Server port (default: 11434)"defaultHeaders   "HTTP headers dictionary"jsonReader       "STON JSON reader"jsonWriter       "STON JSON writer"</code></pre><p><strong>Key Methods</strong>:</p><pre><code>postJsonAt: aPath body: aDictionary    "POST request with JSON payload"    | cl |    cl := ZnClient new.    cl accept: ZnMimeType applicationJson.    cl contentWriter: [:data | ZnEntity json: (jsonWriter toString: data) ].    cl host: host; port: port; path: aPath.    cl forJsonREST.    cl contentReader: [:entity | jsonReader fromString: entity contents ].    cl contents: aDictionary.    ^ cl post.getJsonAt: aPath    "GET request returning JSON"    | cl |    cl := ZnEasy client.    cl forJsonREST; host: host; port: port; path: aPath.    ^ cl get</code></pre><p>---</p><h3>4.3 OModelRegistry (Model Discovery)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Ollama/OModelRegistry.class.st</code></p><p><strong>Purpose</strong>: Registry that builds and looks up available model specs.</p><p><strong>Class Variables</strong>:</p><pre><code>current         "Singleton instance"modelsFetcher   "Optional block to override model fetching"</code></pre><p><strong>Attributes</strong>:</p><pre><code>byFullName    "Dictionary of specs by full name (e.g., 'codellama:7b')"byLabel       "Dictionary of specs by friendly label"</code></pre><p><strong>Key Methods</strong>:</p><pre><code>OModelRegistry class >> refresh    "Rebuild registry from Ollama API"    current := self new.    current rebuild.    ^ currentrebuild    "Fetch models from Ollama and create specs"    | knownSpecs nullSpec |    byFullName := Dictionary new.    byLabel := Dictionary new.    knownSpecs := Dictionary new.        "Collect pragmas"    (Pragma allNamed: #ollamaModel:tag:label:) do: [ :p |        | fam tag label spec full |        fam := p arguments first.        tag := p arguments second.        label := p arguments third.        spec := OModelSpec family: fam tag: tag label: label.        full := spec fullName.        knownSpecs at: full put: spec ].        "Fetch from Ollama"    [ | resp models |        resp := self class fetchModelsResponse.        models := resp at: #models ifAbsent: [ #() ].        models do: [ :m |            | name spec |            name := m at: #name.            spec := knownSpecs at: name ifAbsent: [                self specFromModelName: name ].            self addSpec: spec ]    ] on: Error do: [ :ex | "ignore if server unreachable" ]domainValuesForSettings    "Returns array of label -> fullName associations for UI"    ^ (self allSpecs collect: [ :spec |         spec label -> spec fullName ]) asArray</code></pre><p><strong>Model Spec Format</strong>:</p><pre><code>OModelSpec    family: 'codellama'    "Base model name"    tag: '7b'              "Size/variant tag"    label: 'Code Llama 7B' "Human-readable label"</code></pre><p>---</p><h3>4.4 OModelSpec (Model Specification)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Ollama/OModelSpec.class.st</code></p><p><strong>Purpose</strong>: Represents an Ollama model identified by family, tag, and label.</p><p><strong>Attributes</strong>:</p><pre><code>family    "Base model name (e.g., 'codellama')"tag       "Version/size tag (e.g., '7b')"label     "Human-readable display name"</code></pre><p><strong>Key Methods</strong>:</p><pre><code>fullName    "Returns family:tag format"    ^ tag        ifNil:  [ family ]        ifNotNil: [ family , ':' , tag ]</code></pre><p><strong>Example</strong>:</p><pre><code>spec := OModelSpec     family: 'pharo-coder-1.5b-fim-f16.gguf'     tag: 'latest'     label: 'Pharo Coder 1.5B'.spec fullName.  "=> 'pharo-coder-1.5b-fim-f16.gguf:latest'"spec label.     "=> 'Pharo Coder 1.5B'"</code></pre><p>---</p><h3>4.5 OModelCatalog (Built-in Models)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Ollama/OModelCatalog.class.st</code></p><p><strong>Purpose</strong>: Catalog of built-in Ollama model definitions using pragmas.</p><p><strong>Example Pragma</strong>:</p><pre><code>OModelCatalog class >> pharoCopilotNull    <ollamaModel: 'pharo-copilot-null' tag: nil label: 'Pharo Null Copilot'></code></pre><p>Custom models can be registered by adding methods with the <code><ollamaModel:tag:label:></code> pragma.</p><p>---</p><h2>5. Completion Engine</h2><h3>5.1 Response Cleaning</h3><p>The result builder includes sophisticated response cleaning to handle various LLM output formats:</p><p><strong>Markdown Fence Removal</strong>:</p><pre><code>cleanedContentFrom: aString    "Removes ```language fences and extracts code"    | text start rest closingIndex body |    text := (aString ifNil: [ '' ]) asString.        "Find opening fence"    start := text indexOfSubCollection: '```' startingAt: 1.    start > 0 ifTrue: [        rest := text copyFrom: start + 3 to: text size.        closingIndex := self indexOfClosingFenceIn: rest.        body := rest copyFrom: 1 to: closingIndex - 1.                "Remove language specifier line"        newlineIndex := body indexOf: Character lf.        newlineIndex > 0 ifTrue: [            firstLine := body copyFrom: 1 to: newlineIndex - 1.            (self isLanguageSpec: firstLine) ifTrue: [                body := body copyFrom: newlineIndex + 1 to: body size ] ].        ^ body trimBoth ].        "No fence - return up to double newline"    idx := text indexOfSubCollection: String lf , String lf.    body := idx = 0        ifTrue: [ text ]        ifFalse: [ text copyFrom: 1 to: idx - 1 ].    ^ body trimBoth</code></pre><p><strong>Language Specifier Detection</strong>:</p><pre><code>isLanguageSpec: aString    "Check if line is a language identifier"    | trimmed |    trimmed := aString trimBoth.    ^ (#('smalltalk' 'pharo' 'bash' 'python' 'javascript' 'json' ...)        includes: trimmed asLowercase)        or: [ trimmed allSatisfy: [ :ch |            ch isLetter or: [ ch isDigit or: [ '#+-_' includes: ch ] ] ] ]</code></pre><p>---</p><h3>5.2 Context Extraction</h3><p><strong>Class Context Building</strong>:</p><pre><code>classContextFor: aContext    "Extract comprehensive class information"    | behavior compiledMethod methodClass classDefinition instanceSide classSide |        "Get behavior from context"    behavior := (aContext respondsTo: #behavior)        ifTrue: [ [ aContext behavior ] on: Error do: [ nil ] ]        ifFalse: [ nil ].        "Get method if available"    compiledMethod := (aContext respondsTo: #method)        ifTrue: [ [ aContext method ] on: Error do: [ nil ] ]        ifFalse: [ nil ].        "Determine method class"    methodClass := behavior         ifNil: [ compiledMethod ifNotNil: [ compiledMethod methodClass ] ]         ifNotNil: [ behavior ].        "Build context string"    classDefinition := self safeDefinitionStringFor: methodClass.    instanceSide := self methodSourcesFor: methodClass.    classSide := self methodSourcesFor: (methodClass ifNotNil: [ methodClass class ]).        ^ self        classDefinition: classDefinition        instanceMethods: instanceSide        classMethods: classSide</code></pre><p><strong>Method Sources Extraction</strong>:</p><pre><code>methodSourcesFor: aBehavior    "Collect all method sources from a behavior"    aBehavior ifNil: [ ^ '' ].    ^ String streamContents: [ :stream |        [ (aBehavior selectors asSortedCollection) do: [ :selector |            | source |            source := [ aBehavior sourceCodeAt: selector ]                 on: Error do: [ nil ].            source ifNotNil: [                stream                    nextPutAll: source;                    cr; cr ] ] ]            on: Error do: [ ] ]</code></pre><p>---</p><h2>6. Evaluation System</h2><h3>6.1 CoSuggestionEvaluator (Metrics Tracker)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Evaluator/CoSuggestionEvaluator.class.st</code></p><p><strong>Purpose</strong>: Tracks suggestion acceptance rates and generates comprehensive reports.</p><p><strong>Attributes</strong>:</p><pre><code>acceptedEntries     "OrderedCollection of CoEvaluationEntry"rejectedEntries     "OrderedCollection of CoEvaluationEntry"sessionStats        "Dictionary of current session statistics"persistentStats     "Dictionary of lifetime statistics"</code></pre><p><strong>Class Methods</strong>:</p><pre><code>CoSuggestionEvaluator class >> default    "Singleton instance"    ^ default ifNil: [ default := self new ]</code></pre><p><strong>Key Methods</strong>:</p><pre><code>recordSuggestionAccepted: aCopilotEntry context: aContext    "Record accepted suggestion"    | entry contextType |    entry := CoEvaluationEntry new        suggestion: aCopilotEntry;        context: aContext;        timestamp: DateAndTime now;        action: #accepted;        yourself.    acceptedEntries add: entry.    self updateSessionStats: entry.    self announceEvaluation: entry.recordSuggestionRejected: aCopilotEntry context: aContext reason: reasonString    "Record rejected suggestion with reason"    | entry |    entry := CoEvaluationEntry new        suggestion: aCopilotEntry;        context: aContext;        timestamp: DateAndTime now;        action: #rejected;        rejectionReason: reasonString;        yourself.    rejectedEntries add: entry.    self updateSessionStats: entry.    self announceEvaluation: entry.acceptanceRate    "Calculate percentage of accepted suggestions"    | total accepted |    total := sessionStats at: #totalSuggestions ifAbsent: [ 0 ].    total = 0 ifTrue: [ ^ 0 ].    accepted := sessionStats at: #totalAccepted ifAbsent: [ 0 ].    ^ (accepted / total * 100) rounded</code></pre><p><strong>Session Statistics Structure</strong>:</p><pre><code>sessionStats := Dictionary new    at: #sessionStartTime put: DateAndTime now;    at: #totalSuggestions put: 0;    at: #totalAccepted put: 0;    at: #totalRejected put: 0;    at: #modelStats put: Dictionary new;    at: #contextStats put: Dictionary new;    at: #lengthStats put: Dictionary new;    yourself.</code></pre><p><strong>Context Type Classification</strong>:</p><pre><code>determineContextType: aContext    "Classify the code context"    | src |    src := aContext source.    (self isClassDef: src)         ifTrue: [ ^ #classDef ].    (self isMethodDef: src)        ifTrue: [ ^ #method ].    (self hasTopLevel: '^' in: src)    ifTrue: [ ^ #return ].    (self hasTopLevel: ':=' in: src)   ifTrue: [ ^ #assignment ].    (self hasAnyTopLevel: self iterationSelectors in: src)        ifTrue: [ ^ #iteration ].    (self hasAnyTopLevel: self conditionSelectors in: src)        ifTrue: [ ^ #condition ].    ^ #other</code></pre><p><strong>Export to CSV</strong>:</p><pre><code>exportToCSV: filename    "Export evaluation data for external analysis"    filename asFileReference writeStreamDo: [ :stream |        "Header"        stream nextPutAll: 'Timestamp,Action,Suggestion,Context,Model,Length,Reason'; lf.                "Data rows"        (acceptedEntries , rejectedEntries) do: [ :entry |            stream                 nextPutAll: entry timestamp asString; nextPut: $,;                nextPutAll: entry action asString; nextPut: $,;                nextPutAll: '"', (entry suggestion contents                     copyReplaceAll: '"' with: '""'), '"'; nextPut: $,;                nextPutAll: '"', (entry context source copyFrom: 1                     to: (50 min: entry context source size)), '"'; nextPut: $,;                nextPutAll: CopilotSettings modelName; nextPut: $,;                nextPutAll: entry suggestion contents size asString; nextPut: $,;                nextPutAll: (entry rejectionReason ifNil: [ '' ]); lf ] ]</code></pre><p>---</p><h3>6.2 CoEvaluationReport (Report Generator)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Evaluator/CoEvaluationReport.class.st</code></p><p><strong>Purpose</strong>: Generates comprehensive evaluation reports.</p><p><strong>Report Sections</strong>:</p><ol><li><strong>Overview</strong>: Total suggestions, acceptance rate, rejection rate</li><li><strong>Model Performance</strong>: Statistics per model</li><li><strong>Context Analysis</strong>: Acceptance rates by code context type</li><li><strong>Length Analysis</strong>: Success rates by suggestion length</li><li><strong>Top Rejection Reasons</strong>: Most common rejection causes</li><li><strong>Recommendations</strong>: Actionable insights</li></ol><p><strong>Example Report</strong>:</p><pre><code>=== Copilot Evaluation Report ===OVERVIEW--------Session started: 2025-01-15 14:23:45Total suggestions: 150Accepted: 105 (70%)Rejected: 30 (20%)Ignored: 15MODEL PERFORMANCE----------------pharo-coder-1.5b-fim-f16.gguf:latest: 105/150 accepted (70%)CONTEXT ANALYSIS----------------method: 80/100 accepted (80%)assignment: 15/25 accepted (60%)return: 10/25 accepted (40%)SUGGESTION LENGTH ANALYSIS--------------------------short suggestions: 60/75 accepted (80%)medium suggestions: 35/50 accepted (70%)long suggestions: 10/25 accepted (40%)TOP REJECTION REASONS--------------------Incorrect syntax: 12 timesIncomplete suggestion: 8 timesWrong method name: 5 timesIrrelevant context: 5 timesRECOMMENDATIONS---------------• High acceptance rate - model is performing well• Export data to CSV for detailed analysis: CoSuggestionEvaluator default exportToCSV: 'evaluation.csv'</code></pre><p>---</p><h3>6.3 CoEvaluationEntry (Evaluation Record)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Evaluator/CoEvaluationEntry.class.st</code></p><p><strong>Purpose</strong>: Represents a single evaluation record.</p><p><strong>Attributes</strong>:</p><pre><code>suggestion         "CoCopilotEntry - the suggestion"context            "CoPharoCopilotContext - code context"timestamp          "DateAndTime - when recorded"action             "Symbol - #accepted, #rejected, or #ignored"rejectionReason    "String - why rejected (optional)"metadata           "Dictionary - additional data"</code></pre><p>---</p><h3>6.4 CoEvaluationAnnouncement (Event Notification)</h3><p><strong>Location</strong>: <code>src/AI-Pharo-Copilot-Evaluator/CoEvaluationAnnouncement.class.st</code></p><p><strong>Purpose</strong>: Announcement broadcast when evaluations are recorded.</p><p><strong>Usage</strong>:</p><pre><code>"Listen for evaluation events"SystemAnnouncer uniqueInstance weak    when: CoEvaluationAnnouncement    send: #handleEvaluation:    to: self.handleEvaluation: anAnnouncement    | entry |    entry := anAnnouncement entry.    "Process evaluation..."</code></pre><p>---</p><h2>7. Fill-in-the-Middle (FIM) Templates</h2><h3>7.1 Template System</h3><p>FIM templates define how to format the prompt for models that support fill-in-the-middle completion.</p><p><strong>Template Placeholders</strong>:</p><ul><li><code>{{ .Prompt }}</code> or <code>{{.Prompt}}</code> - Code before cursor (prefix)</li><li><code>{{ .Suffix }}</code> or <code>{{.Suffix}}</code> - Code after cursor (suffix)</li><li><code>{{ .Context }}</code> or <code>{{.Context}}</code> - Class/method context</li><li><code>{1}</code>, <code>{2}</code>, <code>{3}</code> - Positional format strings (prefix, suffix, context)</li></ul><p><strong>Template Expansion</strong>:</p><pre><code>expandFimTemplate: templateString prefix: prefixString     suffix: suffixString context: contextString        | prompt safePrefix safeSuffix safeContext includesContextPlaceholder |    safePrefix := prefixString ifNil: [ '' ] ifNotNil: [ prefixString asString ].    safeSuffix := suffixString ifNil: [ '' ] ifNotNil: [ suffixString asString ].    safeContext := contextString ifNil: [ '' ] ifNotNil: [ contextString asString ].        prompt := templateString ifNil: [ '' ].        "Check if context placeholder exists"    includesContextPlaceholder := (prompt includesSubstring: '{{ .Context }}')        or: [ (prompt includesSubstring: '{{.Context}}')         or: [ prompt includesSubstring: '{3}' ] ].        "Replace placeholders"    prompt := prompt copyReplaceAll: '{{ .Prompt }}' with: safePrefix.    prompt := prompt copyReplaceAll: '{{.Prompt}}' with: safePrefix.    prompt := prompt copyReplaceAll: '{{ .Suffix }}' with: safeSuffix.    prompt := prompt copyReplaceAll: '{{.Suffix}}' with: safeSuffix.    prompt := prompt copyReplaceAll: '{{ .Context }}' with: safeContext.    prompt := prompt copyReplaceAll: '{{.Context}}' with: safeContext.        "Positional format"    prompt := prompt format: { safePrefix. safeSuffix. safeContext }.        "Prepend context if not in template"    (includesContextPlaceholder not and: [ safeContext isEmpty not ])         ifTrue: [ prompt := self prependContext: safeContext toPrompt: prompt ].        ^ prompt</code></pre><p>---</p><h3>7.2 Template Storage</h3><p><strong>Locations</strong>:</p><ol><li><strong>Bundled Templates</strong>: <code>pharo-copilot/templates/</code> directory</li><li><strong>Cached Templates</strong>: <code>pharo-copilot/copilot-logs/{model-name}/template.txt</code></li></ol><p><strong>Template Discovery</strong>:</p><pre><code>CopilotSettings class >> defaultFimTemplate    "Returns FIM template for current model"    | template cacheFile |        "Try cached template first"    cacheFile := self templateFileForModelNamed: self modelName.    template := self fimTemplateFromFile: cacheFile.    template ifNotNil: [ ^ template ].        "Fall back to bundled templates"    template := self fimTemplateFromBundledTemplates.    template ifNotNil: [ ^ template ].        "Error if no template found"    self logMissingFimTemplate.    ^ self error: 'No fill-in-the-middle template is available         for the current Copilot model.'</code></pre><p><strong>Example Template</strong> (CodeLlama format):</p><pre><code><PRE> {{ .Prompt }} <SUF> {{ .Suffix }} <MID></code></pre><p><strong>Example Template</strong> (Pharo Coder format):</p><pre><code>Complete the following Smalltalk code:Class Context:{{ .Context }}Code to complete:{{ .Prompt }}<FILL>{{ .Suffix }}Completion:</code></pre><p>---</p><h3>7.3 Model Metadata</h3><p>Model metadata is fetched from Ollama and cached locally:</p><p><strong>Fetch Metadata</strong>:</p><pre><code>CopilotSettings class >> fetchModelMetadata    "Query model details from Ollama"    | client response metadata |    client := self newOllamaClient.        [ response := client showModelNamed: self modelName.      metadata := self populateMetadata: Dictionary new fromResponse: response.      self saveModelMetadataToDisk: metadata forModel: self modelName.    ] on: Error do: [ :ex |        metadata := self nullModelMetadata ].        ^ metadata</code></pre><p><strong>Metadata Structure</strong>:</p><pre><code>metadata := Dictionary new    at: #model put: 'pharo-coder-1.5b-fim-f16.gguf:latest';    at: #template put: '<PRE> {1} <SUF> {2} <MID>';    at: #system put: 'You are a Smalltalk code completion assistant...';    at: #parameters put: '{"temperature": 0.3, ...}';    at: #modelfile put: 'FROM pharo-coder-1.5b-fim-f16.gguf...';    yourself.</code></pre><p>---</p><h2>8. Installation & Setup</h2><h3>8.1 Prerequisites</h3><ol><li><strong>Pharo 13 or 14</strong>: Download from <a target="_blank" href="https://pharo.org/">pharo.org</a></li><li><strong>Ollama</strong>: Install from <a target="_blank" href="https://ollama.com/">ollama.com</a></li><li><strong>Git</strong> (optional): For cloning repository</li></ol><p>---</p><h3>8.2 Installation</h3><p><strong>Option 1: Metacello (Recommended)</strong></p><pre><code>"Latest stable release"Metacello new    repository: 'github://omarabedelkader/Pharo-Copilot:main/src';    baseline: 'PharoCopilot';    load.**Option 2: Manual Loading**</code></pre><p>"Clone repository and load packages"<br>repo := IceRepositoryCreator new<br>location: '/path/to/pharo-copilot';<br>createRepository.</p><p>"Load packages in order"</p><h1>(</h1><p>'AI-Pharo-Copilot'<br>'AI-Pharo-Copilot-Ollama'<br>'AI-Pharo-Copilot-Evaluator'<br>'AI-Pharo-Copilot-Tests'<br>) do: [ :pkgName |<br>Metacello new<br>baseline: pkgName;<br>repository: 'gitlocal:///path/to/pharo-copilot';<br>load ].</p><pre><code>---### 8.3 Ollama Setup**1. Install Ollama**</code></pre><h1>macOS/Linux</h1><p>curl <a target="_blank" href="https://ollama.ai/install.sh">https://ollama.ai/install.sh</a> | sh</p><h1>Windows</h1><h1>Download installer from ollama.com</h1><pre><code>**2. Start Ollama Service**</code></pre><p>ollama serve</p><pre><code>**3. Pull Recommended Model**</code></pre><h1>Recommended for Pharo</h1><p>ollama pull pharo-coder-1.5b-fim-f16.gguf:latest</p><h1>Alternative: CodeLlama</h1><p>ollama pull codellama:7b</p><pre><code>**4. Verify Installation**</code></pre><h1>List installed models</h1><p>ollama list</p><h1>Test model</h1><p>ollama run pharo-coder-1.5b-fim-f16.gguf:latest "Hello"</p><pre><code>---### 8.4 Initial Configuration**1. Enable Copilot Engine**</code></pre><p>"Set as active completion engine"<br>RubSmalltalkEditor completionEngineClass: CoCompletionEnginePharoCopilot.</p><p>"Verify"<br>RubSmalltalkEditor completionEngineClass.<br>"=> CoCompletionEnginePharoCopilot"</p><pre><code>**2. Configure Settings**</code></pre><p>"Enable copilot"<br>CopilotSettings copilotEnabled: true.</p><p>"Set provider"<br>CopilotSettings copilotProvider: #ollama.</p><p>"Select model"<br>CopilotSettings modelName: 'pharo-coder-1.5b-fim-f16.gguf:latest'.</p><p>"Configure host/port (defaults: 127.0.0.1:11434)"<br>CopilotSettings host: '127.0.0.1'.<br>CopilotSettings port: 11434.</p><p>"Enable logging"<br>CopilotSettings loggingEnabled: true.</p><p>"Enable auto-install"<br>CopilotSettings autoInstallModelScriptEnabled: true.</p><pre><code>**3. Test Connection**</code></pre><p>"Verify Ollama is reachable"<br>client := OllamaClient new.<br>models := client listModels.<br>models inspect.</p><p>"Test generation"<br>client generate: 'Hello, world!'.</p><pre><code>---### 8.5 System Settings UIAccess settings through Pharo's Settings Browser:1. Open **Settings Browser**: `Settings > System Settings`2. Navigate to **Code Browsing > Copilot**3. Configure:   - **Provider**: Select `ollama`   - **Model**: Choose from dropdown (auto-populated from Ollama)   - **Enable logging**: Check to enable activity logs   - **Auto-install model**: Check to auto-pull recommended model   - **Server host**: Default `127.0.0.1`   - **Server port**: Default `11434`---## 9. Usage Guide### 9.1 Basic Completion**1. Open a Browser/Playground**</code></pre><p>"Open System Browser"<br>Smalltalk tools browser open.</p><p>"Or Playground"<br>Smalltalk tools playground open.</p><pre><code>**2. Start Typing Code**</code></pre><p>Object subclass: #MyClass<br>instanceVariableNames: 'name age'<br>classVariableNames: ''<br>package: 'MyPackage'</p><p>MyClass >> initialize<br>super initialize.<br>"Place cursor here and wait for suggestions"</p><pre><code>**3. Accept Suggestion**- Suggestion appears automatically after brief pause- Press **Tab** to accept- Press **Esc** to reject- Continue typing to ignore---### 9.2 Context-Aware CompletionCopilot provides better suggestions with more context:**Example 1: Method Completion**</code></pre><p>"Given class:"<br>Person >> initialize<br>super initialize.<br>name := ''.<br>age := 0.</p><p>"Type this:"<br>Person >> description<br>"Copilot suggests:"<br>^ String streamContents: [ :s |<br>s nextPutAll: 'Person: '.<br>s nextPutAll: name.<br>s nextPutAll: ', Age: '.<br>s nextPutAll: age asString ]</p><pre><code>**Example 2: Iterating Collections**</code></pre><p>"Type this:"<br>collection := #(1 2 3 4 5).<br>collection collect: [ :each |<br>"Copilot suggests:"<br>each squared ]</p><pre><code>**Example 3: Conditional Logic**</code></pre><p>"Type this:"<br>value ifNil: [<br>"Copilot suggests:"<br>^ self defaultValue ]<br>ifNotNil: [ :v |<br>^ v + 1 ]</p><pre><code>---### 9.3 Fill-in-the-MiddleCopilot uses FIM to complete code in the middle of a method:</code></pre><p>"Before cursor:"<br>MyClass >> processData<br>| result |<br>result := data collect: [ :item | item * 2 ].<br>"Place cursor here"</p><p>"After cursor:"<br>^ result</p><p>"Copilot suggests between lines:"<br>result := result select: [ :each | each > 10 ].</p><pre><code>---### 9.4 Evaluation & Feedback**Track Your Usage**:</code></pre><p>"View session statistics"<br>CoSuggestionEvaluator default sessionStats inspect.</p><p>"Generate report"<br>report := CoSuggestionEvaluator default generateReport.<br>report inspect.</p><p>"Export to CSV"<br>CoSuggestionEvaluator default exportToCSV: 'copilot-evaluation.csv'.</p><p>"Check acceptance rate"<br>CoSuggestionEvaluator default acceptanceRate.<br>"=> 75"</p><pre><code>**Manual Rejection**:</code></pre><p>"If you want to explicitly mark a suggestion as rejected"<br>entry := CoCopilotEntry contents: 'bad suggestion'.<br>context := CoPharoCopilotContext new.<br>CoSuggestionEvaluator default<br>recordSuggestionRejected: entry<br>context: context<br>reason: 'Incorrect syntax'.</p><pre><code>---### 9.5 Viewing Logs**Activity Log**:</code></pre><p>"Open log file"<br>logFile := CoCopilotLogger logFileReference.<br>logFile exists ifTrue: [<br>logFile openWithShell ].</p><p>"Or inspect contents"<br>logFile contents inspect.</p><pre><code>**Evaluation Log (JSONL)**:</code></pre><p>"Open evaluation log"<br>evalLog := CoCopilotLogger evaluationLogFileReference.<br>evalLog exists ifTrue: [<br>evalLog openWithShell ].</p><p>"Parse JSON lines"<br>lines := evalLog contents lines.<br>entries := lines collect: [ :line |<br>STONJSON fromString: line ].<br>entries inspect.</p><pre><code>---## 10. Configuration & Settings### 10.1 CopilotSettings (Global Configuration)**Location**: `src/AI-Pharo-Copilot-Ollama/CopilotSettings.class.st`**Class Variables**:</code></pre><p>Enabled                        "Boolean - enable/disable copilot"<br>Provider                       "Symbol - backend provider (#ollama)"<br>ModelName                      "String - selected model full name"<br>Host                           "String - Ollama server host"<br>Port                           "Integer - Ollama server port"<br>ModelMetadata                  "Dictionary - cached model info"<br>OllamaClientFactory            "Block - factory for creating clients"<br>AutoInstallModelScriptEnabled  "Boolean - auto-pull missing models"<br>LoggingEnabled                 "Boolean - enable activity logging"<br>TemplatesDirectory             "FileReference - FIM templates location"</p><pre><code>**Key Methods**:</code></pre><p>CopilotSettings class >> copilotEnabled<br>"Check if copilot is enabled"<br>^ Enabled ifNil: [ Enabled := true ].</p><p>CopilotSettings class >> copilotEnabled: aBool<br>"Enable/disable copilot"<br>Enabled := aBool.</p><p>CopilotSettings class >> modelName<br>"Get current model name"<br>^ ModelName ifNil: [ ModelName := OllamaClient defaultModelFullName ]</p><p>CopilotSettings class >> modelName: aString<br>"Set model and clear cached metadata"<br>ModelName := aString.<br>self clearCachedModelMetadata.</p><p>CopilotSettings class >> availableModelNames<br>"Returns array of label->fullName pairs for UI"<br>^ OModelRegistry refresh domainValuesForSettings</p><p>CopilotSettings class >> newOllamaClient<br>"Create new Ollama client instance"<br>^ self ollamaClientFactory value</p><pre><code>---### 10.2 Model Auto-InstallationWhen configured model is missing, Copilot can automatically pull it from Ollama:**Configuration**:</code></pre><p>"Enable auto-install for recommended model"<br>CopilotSettings autoInstallModelScriptEnabled: true.</p><pre><code>**Auto-Install Process**:</code></pre><p>CopilotSettings class >> attemptAutoInstallForModelNamed: modelName<br>usingInitialResponse: response<br><br>"Check if auto-install is enabled and model is recommended"<br>(self shouldAutoInstallModelNamed: modelName) ifFalse: [ ^ false ].<br><br>"Log attempt"<br>CoCopilotLogger<br>logBackEndEvent: 'Attempting auto-install for missing Ollama model'<br>details: (Dictionary new<br>at: #model put: modelName;<br>at: #availableModelsBefore put: (self modelNamesFromResponse: response);<br>yourself).<br><br>"Run install script"<br>(self installModelNamed: modelName) ifFalse: [ ^ false ].<br><br>"Verify model is now available"<br>[ | refreshedResponse refreshedModels |<br>refreshedResponse := self newOllamaClient listModels.<br>refreshedModels := self modelNamesFromResponse: refreshedResponse.<br>(refreshedModels includes: modelName) ifTrue: [<br>OModelRegistry refresh.<br>^ true ].<br>] on: Error do: [ :ex | self logError: ex ].<br><br>^ false</p><pre><code>**Recommended Model**:</code></pre><p>CopilotSettings class >> shouldAutoInstallModelNamed: modelName<br>(self autoInstallModelScriptEnabled) ifFalse: [ ^ false ].<br>modelName ifNil: [ ^ false ].<br>^ modelName = 'pharo-coder-1.5b-fim-f16.gguf:latest'</p><pre><code>---### 10.3 Custom Client FactoryFor testing or custom backends, override the client factory:</code></pre><p>"Use mock client for testing"<br>CopilotSettings ollamaClientFactory: [ MockOllamaClient new ].</p><p>"Restore default"<br>CopilotSettings ollamaClientFactory: [ OllamaClient new ].</p><pre><code>---### 10.4 Settings Snapshot & Restore**Snapshot Current Settings**:</code></pre><p>snapshot := CopilotSettings settingsSnapshot.<br>"=> Dictionary with all settings"</p><pre><code>**Restore Settings**:</code></pre><p>CopilotSettings restoreSettingsFromSnapshot: snapshot.</p><pre><code>**Temporary Settings**:</code></pre><p>"Execute block with default settings"<br>CopilotSettings withDefaultSettingsDo: [<br>"Your code here - settings are reset"<br>client := OllamaClient new.<br>client generate: 'test prompt' ].</p><p>"Settings restored automatically after block"</p><pre><code>---## 11. Extension Points### 11.1 Custom Models**Register Model via Pragma**:</code></pre><p>MyModelCatalog class >> myCustomModel<br><ollamaModel: 'mycustom' tag: 'v1' label: 'My Custom Model'></p><pre><code>**After registration**:</code></pre><p>"Refresh registry to pick up new pragmas"<br>OModelRegistry refresh.</p><p>"Model appears in settings dropdown"<br>CopilotSettings availableModelNames.<br>"=> includes: 'My Custom Model' -> 'mycustom:v1'"</p><pre><code>---### 11.2 Custom FIM Templates**Create Template File**:</code></pre><p>pharo-copilot/templates/mycustom-v1-template.txt</p><pre><code>**Template Content**:</code></pre><p><|fim<i>prefix|> .Prompt <|fim</i>suffix|> .Suffix <|fim_middle|></p><pre><code>**Or provide via code**:</code></pre><p>"Override template method"<br>CopilotSettings class >> fimTemplateForModel: modelName<br>modelName = 'mycustom:v1' ifTrue: [<br>^ '<|fim<i>prefix|>{1}<|fim</i>suffix|>{2}<|fim_middle|>' ].<br>^ super fimTemplateForModel: modelName</p><pre><code>---### 11.3 Custom Result Processing**Subclass Result Builder**:</code></pre><p>CoPharoCopilotResultSetBuilder subclass: #MyCustomResultSetBuilder<br>instanceVariableNames: ''<br>classVariableNames: ''<br>package: 'MyExtension'</p><p>MyCustomResultSetBuilder >> cleanedContentFrom: aString<br>"Custom cleaning logic"<br>| cleaned |<br>cleaned := super cleanedContentFrom: aString.<br><br>"Additional processing"<br>cleaned := self removeComments: cleaned.<br>cleaned := self formatCode: cleaned.<br><br>^ cleaned</p><pre><code>**Use Custom Builder**:</code></pre><p>CoPharoCopilotContext >> initialize<br>super initialize.<br>completionBuilder := MyCustomResultSetBuilder initializeOnContext: self</p><pre><code>---### 11.4 Evaluation Listeners**Subscribe to Evaluation Events**:</code></pre><p>Object subclass: #MyEvaluationListener<br>instanceVariableNames: ''<br>classVariableNames: ''<br>package: 'MyExtension'</p><p>MyEvaluationListener >> initialize<br>super initialize.<br>SystemAnnouncer uniqueInstance weak<br>when: CoEvaluationAnnouncement<br>send: #handleEvaluation:<br>to: self.</p><p>MyEvaluationListener >> handleEvaluation: anAnnouncement<br>| entry |<br>entry := anAnnouncement entry.<br><br>entry action = #accepted ifTrue: [<br>"Log accepted suggestion to external service"<br>self logToExternalService: entry ].<br><br>entry action = #rejected ifTrue: [<br>"Analyze rejection for improvement"<br>self analyzeRejection: entry ]</p><pre><code>---## 12. Troubleshooting### 12.1 Common Issues**Issue 1: "Ollama service unavailable"****Symptoms**: No completions, error in log**Checks**:</code></pre><h1>Verify Ollama is running</h1><p>ps aux | grep ollama</p><h1>Test API</h1><p>curl <a target="_blank" href="http://127.0.0.1:11434/api/tags">http://127.0.0.1:11434/api/tags</a></p><h1>Check port</h1><p>lsof -i :11434</p><pre><code>**Solutions**:</code></pre><h1>Start Ollama</h1><p>ollama serve</p><h1>Or restart service</h1><p>pkill ollama && ollama serve</p><pre><code>---**Issue 2: "Model not found"****Symptoms**: Error message, null model fallback**Checks**:</code></pre><h1>List installed models</h1><p>ollama list</p><h1>Check if model exists in Ollama</h1><p>ollama show pharo-coder-1.5b-fim-f16.gguf:latest</p><pre><code>**Solutions**:</code></pre><h1>Pull missing model</h1><p>ollama pull pharo-coder-1.5b-fim-f16.gguf:latest</p><h1>Or enable auto-install</h1><pre><code></code></pre><p>CopilotSettings autoInstallModelScriptEnabled: true.</p><pre><code>---**Issue 3: "No completions appearing"****Checks**:</code></pre><p>"Verify copilot is enabled"<br>CopilotSettings copilotEnabled.</p><p>"Check completion engine"<br>RubSmalltalkEditor completionEngineClass.<br>"Should be: CoCompletionEnginePharoCopilot"</p><p>"Test client manually"<br>client := OllamaClient new.<br>client generate: 'test'.</p><pre><code>**Solutions**:</code></pre><p>"Enable copilot"<br>CopilotSettings copilotEnabled: true.</p><p>"Set correct engine"<br>RubSmalltalkEditor completionEngineClass: CoCompletionEnginePharoCopilot.</p><p>"Refresh model registry"<br>OModelRegistry refresh.</p><pre><code>---**Issue 4: "Slow completions"****Checks**:</code></pre><p>"Check if large context is being sent"<br>CoCopilotLogger logFileReference contents inspect.<br>"Look for 'classContextLength' in logs"</p><pre><code>**Solutions**:</code></pre><h1>Use smaller, faster model</h1><p>ollama pull codellama:7b  # Instead of 34b</p><h1>Or use quantized model</h1><p>ollama pull pharo-coder-1.5b-fim-f16.gguf:latest  # Optimized</p><pre><code></code></pre><p>"Reduce context size (future enhancement)"<br>"Currently sends all methods - consider filtering"</p><pre><code>---**Issue 5: "Template not found"****Symptoms**: Error about missing FIM template**Checks**:</code></pre><p>"Check template file"<br>CopilotSettings templateFileForModelNamed: CopilotSettings modelName.<br>"Check if file exists"</p><p>"Check bundled templates"<br>CopilotSettings templatesDirectory entries inspect.</p><pre><code>**Solutions**:</code></pre><p>"Fetch metadata to create cached template"<br>CopilotSettings fetchModelMetadata.</p><p>"Or create template manually"<br>templateFile := CopilotSettings templateFileForModelNamed: CopilotSettings modelName.<br>templateFile parent ensureCreateDirectory.<br>templateFile writeStreamDo: [ :s |<br>s nextPutAll: '<PRE> {1} <SUF> {2} <MID>' ].</p><pre><code>---### 12.2 Debugging**Enable Verbose Logging**:</code></pre><p>"Ensure logging is enabled"<br>CopilotSettings loggingEnabled: true.</p><p>"Check log location"<br>CoCopilotLogger logFileReference fullName.<br>"=> '/path/to/pharo-copilot/copilot-logs/copilot.log'"</p><p>"Tail log file"<br>CoCopilotLogger logFileReference contents inspect.</p><pre><code>**Inspect Internal State**:</code></pre><p>"Check settings"<br>CopilotSettings settingsSnapshot inspect.</p><p>"Check current model"<br>client := OllamaClient new.<br>client instVarNamed: 'modelSpec'.</p><p>"Check evaluator stats"<br>CoSuggestionEvaluator default sessionStats inspect.</p><p>"Check registry"<br>OModelRegistry current allSpecs inspect.</p><pre><code>**Manual Completion Test**:</code></pre><p>"Create mock context"<br>context := CoPharoCopilotContext new.<br>context source: 'Object subclass: #Test'.</p><p>"Build completion manually"<br>builder := CoPharoCopilotResultSetBuilder new.<br>builder initializeOnContext: context.</p><p>"Extract context"<br>classContext := builder classContextFor: context.<br>classContext inspect.</p><p>"Test with client"<br>client := OllamaClient new.<br>response := client generateForPrefix: 'Object >> test' suffix: '' context: classContext.<br>response inspect.</p><pre><code>---### 12.3 Reset & Clean Start**Reset Settings to Default**:</code></pre><p>CopilotSettings resetToDefaultSettings.</p><pre><code>**Clear Caches**:</code></pre><p>"Clear model metadata cache"<br>CopilotSettings clearCachedModelMetadata.</p><p>"Reset model registry"<br>OModelRegistry reset.<br>OModelRegistry refresh.</p><p>"Reset evaluator"<br>CoSuggestionEvaluator reset.</p><pre><code>**Delete Logs**:</code></pre><p>"Delete activity log"<br>CoCopilotLogger logFileReference delete.</p><p>"Delete evaluation log"<br>CoCopilotLogger evaluationLogFileReference delete.</p><p>"Re-initialize logger"<br>CoCopilotLogger initialize.</p><pre><code>---## 13. Testing Suite### 13.1 Test Organization**Test Packages**:- **AI-Pharo-Copilot-Tests**: Main test suite- **AI-Pharo-Copilot-Tests-Mock**: Mock infrastructure**Test Categories**:1. **Unit Tests**: Component-level testing2. **Integration Tests**: Cross-component workflows3. **Regression Tests**: Prevent known issues4. **Usability Tests**: User experience validation5. **Stress Tests**: Performance and scalability6. **Advanced Tests**: Complex evaluation scenarios---### 13.2 Mock Infrastructure**CopilotMockModelTestCase**:Base test case that sets up mock models:</code></pre><p>CopilotMockModelTestCase >> setUp<br>super setUp.<br>mockContext := OTestModelSupport beginMockModels.</p><p>CopilotMockModelTestCase >> tearDown<br>[ super tearDown ] ensure: [<br>OTestModelSupport endMockModels: mockContext.<br>mockContext := nil ].</p><pre><code>**OTestModelSupport**:Utility class for mock model management:</code></pre><p>OTestModelSupport class >> beginMockModels<br>"Setup mock models for testing"<br>| context originalFetcher |<br>context := Dictionary new.<br><br>"Save original fetcher"<br>originalFetcher := OModelRegistry modelsFetcher.<br>context at: #originalFetcher put: originalFetcher.<br><br>"Install mock fetcher"<br>OModelRegistry modelsFetcher: [<br>self mockModelsResponse ].<br><br>"Refresh registry with mocks"<br>OModelRegistry refresh.<br><br>^ context</p><p>OTestModelSupport class >> endMockModels: context<br>"Restore original state"<br>| originalFetcher |<br>originalFetcher := context at: #originalFetcher ifAbsent: [ nil ].<br>OModelRegistry modelsFetcher: originalFetcher.<br>OModelRegistry refresh.</p><p>OTestModelSupport class >> mockModelsResponse<br>"Returns mock models list"<br>^ Dictionary new<br>at: #models put: #(<br>#{ #name -> 'mock:model' }<br>#{ #name -> 'test:7b' }<br>);<br>yourself</p><pre><code>---### 13.3 Key Test Classes**OAHttpTransportTest**:Tests HTTP transport layer:</code></pre><p>testDefaultHostAndPort<br>| transport |<br>transport := OAHttpTransport new.<br>self assert: transport host equals: '127.0.0.1'.<br>self assert: transport port equals: 11434.</p><p>testJsonReaderWriterInitialization<br>| transport |<br>transport := OAHttpTransport new.<br>self assert: transport jsonReader notNil.<br>self assert: transport jsonWriter notNil.</p><pre><code>**CopilotSettingsValidationTest**:Tests settings validation:</code></pre><p>testModelNameWithInvalidValues<br>| old longName |<br>old := CopilotSettings modelName.<br>[<br>"Empty string should not crash"<br>CopilotSettings modelName: ''.<br>self assert: CopilotSettings modelName equals: ''.<br><br>"Long name"<br>longName := String new: 1000 withAll: $m.<br>CopilotSettings modelName: longName.<br>self assert: CopilotSettings modelName equals: longName.<br>] ensure: [ CopilotSettings modelName: old ]</p><pre><code>**UsabilityTest**:Tests user experience:</code></pre><p>testEntryDisplayStringIsInformative<br>| shortEntry longEntry |<br>shortEntry := CoCopilotEntry contents: 'def method'.<br>longEntry := CoCopilotEntry contents: (String new: 200 withAll: $x).<br><br>"Short content shown completely"<br>self assert: shortEntry displayString equals: 'def method'.<br><br>"Long content truncated with indicator"<br>self assert: longEntry displayString size < 200.<br>self assert: (longEntry displayString endsWith: '…').</p><p>testAvailableModelNamesAreUserFriendly<br>| modelNames |<br>modelNames := CopilotSettings availableModelNames.<br>modelNames do: [ :assoc |<br>"Keys should be human-readable labels"<br>self assert: assoc key isString.<br>self deny: assoc key isEmpty.<br>"Labels should be more readable than identifiers"<br>self deny: assoc key equals: assoc value ]</p><pre><code>**RegressionTest**:Tests for known issues:</code></pre><p>testCleanedContentFromDoesNotAlterOriginalString<br>| builder original result |<br>builder := CoPharoCopilotResultSetBuilder new.<br>original := '<code></code><code>smalltalk', String lf, 'original code', String lf, '</code><code></code>'.<br>result := builder cleanedContentFrom: original.<br><br>"Original unchanged"<br>self assert: (original includesSubstring: '<code></code>`smalltalk').<br>self assert: result equals: 'original code'.</p><p>testDefaultModelConsistency<br>| defaultModel client1 client2 |<br>defaultModel := OllamaClient defaultModelFullName.<br>client1 := OllamaClient new.<br>client2 := OllamaClient new.<br><br>"Both clients use same model"<br>self assert: (client1 instVarNamed: 'modelSpec') fullName equals: defaultModel.<br>self assert: (client2 instVarNamed: 'modelSpec') fullName<br>equals: (client1 instVarNamed: 'modelSpec') fullName.</p><pre><code>**CoSuggestionEvaluatorAdvancedTest**:Tests evaluation system:</code></pre><p>testComplexEvaluationScenario<br>| evaluator context suggestions lengthStats |<br>evaluator := CoSuggestionEvaluator new.<br>context := CoPharoCopilotContext new.<br><br>"Create variety of suggestions"<br>suggestions := {<br>CoCopilotEntry contents: 'short'.<br>CoCopilotEntry contents: (String new: 30 withAll: l) }.<br><br>"Record actions"<br>evaluator recordSuggestionAccepted: suggestions first context: context.<br>evaluator recordSuggestionIgnored: suggestions second context: context.<br>evaluator recordSuggestionAccepted: suggestions third context: context.<br><br>"Verify statistics"<br>self assert: (evaluator sessionStats at: #totalSuggestions) equals: 3.<br>self assert: (evaluator sessionStats at: #totalAccepted) equals: 2.<br>self assert: evaluator acceptanceRate equals: 67.</p><pre><code>**OModelRegistryStressTest**:Tests scalability:</code></pre><p>testMassiveModelRegistry<br>| registry |<br>registry := OModelRegistry new.<br><br>1 to: 100 do: [:i |<br>| spec |<br>spec := OModelSpec<br>family: ('model', i asString)<br>tag:    ('v', i asString)<br>label:  ('Model ', i asString).<br>registry addSpec: spec ].<br><br>self assert: registry byFullName size equals: 100.<br>self assert: registry byLabel size equals: 100.<br>self assert: registry allSpecs size equals: 100.</p><pre><code>---### 13.4 Running Tests**Run All Tests**:</code></pre><p>"Run all copilot tests"<br>testRunner := TestRunner new.<br>testRunner selectPackage: 'AI-Pharo-Copilot-Tests'.<br>testRunner runAll.</p><p>"Or use SUnit"<br>(TestCase allSubclasses select: [ :tc |<br>tc category includesSubstring: 'Copilot' ]) do: [ :tc |<br>tc suite run ].</p><pre><code>**Run Specific Test Class**:</code></pre><p>"Run single test class"<br>UsabilityTest suite run.</p><p>"Run specific test"<br>UsabilityTest new testEntryDisplayStringIsInformative.</p><pre><code>**CI Integration**:</code></pre><h1>Run tests from command line</h1><p>pharo Pharo.image test --junit-xml-output 'AI-Pharo-Copilot-Tests'</p><pre><code>---## Appendix A: Class Reference### Core Package (AI-Pharo-Copilot)| Class | Purpose ||-------|---------|| **CoCompletionEnginePharoCopilot** | Main completion engine integration || **CoPharoCopilotResultSetBuilder** | Builds completion result sets || **CoPharoCopilotContext** | Specialized completion context || **CoCopilotEntry** | Single completion suggestion || **CoCopilotLogger** | Centralized activity logging |### Ollama Package (AI-Pharo-Copilot-Ollama)| Class | Purpose ||-------|---------|| **OllamaClient** | REST API client for Ollama || **OAHttpTransport** | HTTP transport layer || **CopilotSettings** | Global configuration || **OModelRegistry** | Model discovery and management || **OModelSpec** | Model specification || **OModelCatalog** | Built-in model definitions |### Evaluator Package (AI-Pharo-Copilot-Evaluator)| Class | Purpose ||-------|---------|| **CoSuggestionEvaluator** | Tracks suggestion metrics || **CoEvaluationReport** | Generates evaluation reports || **CoEvaluationEntry** | Single evaluation record || **CoEvaluationAnnouncement** | Evaluation event notification |### Test Package (AI-Pharo-Copilot-Tests)| Class | Purpose ||-------|---------|| **CopilotMockModelTestCase** | Base test with mock setup || **OTestModelSupport** | Mock infrastructure utilities || **OAHttpTransportTest** | Tests HTTP transport || **CopilotSettingsValidationTest** | Tests settings validation || **UsabilityTest** | Tests user experience || **RegressionTest** | Tests for known issues || **CoSuggestionEvaluatorAdvancedTest** | Tests evaluation system || **OModelRegistryStressTest** | Tests scalability |---## Appendix B: Configuration Files### Directory Structure</code></pre><p>pharo-image-directory/<br>├── pharo-copilot/<br>│   ├── templates/                    # FIM templates<br>│   │   ├── codellama-7b-template.txt<br>│   │   ├── pharo-coder-template.txt<br>│   │   └── ...<br>│   └── copilot-logs/                 # Activity logs<br>│       ├── copilot.log               # Main activity log<br>│       ├── copilot-evaluation-log.jsonl  # Evaluation data<br>│       └── {model-name}/             # Per-model metadata<br>│           ├── template.txt<br>│           ├── system.txt<br>│           ├── parameters.txt<br>│           └── modelfile.txt</p><pre><code>### Log File Formats**Activity Log** (`copilot.log`):</code></pre><p>===== [FRONTEND] Preparing completion request @ 2025-01-15 14:23:45 =====<br>- contextClass: CoPharoCopilotContext<br>- cursorPosition: 45<br>- sourceSize: 120</p><p>===== [BACKEND] Dispatching generate request @ 2025-01-15 14:23:46 =====<br>- endpoint: api/generate<br>- modelFullName: pharo-coder-1.5b-fim-f16.gguf:latest</p><pre><code>**Evaluation Log** (`copilot-evaluation-log.jsonl`):</code></pre>
	
	
<br>
<p>
  © 2025 Omar AbedelKader
</p>
	
	</div>
	
	</body>
	

</html>